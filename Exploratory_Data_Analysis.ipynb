{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Emotions in Headlines\n",
    "\n",
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Kelly Epley\n",
    "\n",
    "\n",
    "In this notebook, I explore the label distributions and word frequencies in the dataset. In the process, I illustrate some of the challenges associated with doing sentiment and emotion analysis well.\n",
    "\n",
    "### About the Data\n",
    "\n",
    "link to data: http://web.eecs.umich.edu/~mihalcea/affectivetext/\n",
    "\n",
    "\n",
    "### Organization\n",
    "\n",
    "I used a custom function to organize my data into a corpus DataFrame and two sets of targets: emotions and valences. There is also a separate validation set. See the file named \"get_labeled_dfs\" for details.\n",
    "\n",
    "The emotion target is a set of intensity ratings for six emotion categories on a scale of 0 to 100. The categories are: anger, disgust, fear, joy, sadness, and surprise. The valence target is a single valence rating between -100 and 100. \n",
    "\n",
    "I added a \"label\" column to each target DataFrame. The labels in \"emotion_df\" represent the emotion with the highest intensity rating for each headline. The labels in \"valence_df\" represent negative ratings beween -100 and -15, positive raings between 15 and 100, and low valence/neutral ratings in the middle. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary packages and custom functions, classes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.util import bigrams\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "from get_labeled_dfs import *\n",
    "from process_text import *\n",
    "from get_emotion_wordcount import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom function to get the corpus df, label dfs, and validation dfs\n",
    "corpus_df, val_corpus_df, emotion_df, val_emotion_df, valence_df, val_valence_df = get_labeled_dfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test to predict breast cancer relapse is approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two Hussein allies are hanged, Iraqi official ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sights and sounds from CES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schuey sees Ferrari unveil new car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Closings and cancellations top advice on flu o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Test to predict breast cancer relapse is approved\n",
       "1  Two Hussein allies are hanged, Iraqi official ...\n",
       "2                         Sights and sounds from CES\n",
       "3                 Schuey sees Ferrari unveil new car\n",
       "4  Closings and cancellations top advice on flu o..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head()\n",
    "# corpus_df.to_csv('corpus_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   valence  label\n",
       "0       32      1\n",
       "1      -48      0\n",
       "2       26      1\n",
       "3       40      1\n",
       "4       -6      2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valence_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>max</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>joy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>fear</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  disgust  fear  joy  sadness  surprise      max  label\n",
       "0      0        0    15   38        9        11      joy      3\n",
       "1     24       26    16   13       38         5  sadness      4\n",
       "2      0        0     0   17        0         4      joy      3\n",
       "3      0        0     0   46        0        31      joy      3\n",
       "4      1        0    23    8       11         8     fear      2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence of Emotion Words\n",
    "\n",
    "One obvious strategy for detecting emotions in text is to look for the presence of emotion words such as \"happy,\" \"sad,\" and \"afraid.\"\n",
    "\n",
    "To explore this strategy, I used a list of emotion words from WordNet ([described here](http://wndomains.fbk.eu/wnaffect.html)) and counted the instances of these words in each headline to see whether the words in the list correspond with their emotion ratings.\n",
    "\n",
    "Here are a few examples of what I found:\n",
    "\n",
    "* Sometimes the words accurately track a headline's emotion rating: The words \"tirade\" and \"outrage\" and from the anger words list appear in the headline \"Israeli woman's tirade spurs PM outrage,\" which received a score of 71 for anger.\n",
    "\n",
    "* Sometimes the words do not accurately track a headline's emotion rating: The word \"aggressive\" from the anger list appears in the headline \"Bigger, more aggressive rats infesting UK,\" which received only a 4 for anger. It's highest scores were 56 for fear and 54 for disgust. \n",
    "\n",
    "* Sometimes words appearing in the emotion word lists have alternative meanings that are neutral or have different emotional import: The word \"offensive from the disgust list appears in the headline \"US to urge Nato Afghan spring offensive.\" The word \"offensive\" in this headline means: taking an action against an opponent. It likely appears in the disgust list for its other meaning: causing someone to be insulted by a slight or a breach of social expectations. The headline receives its highest rating of 54 for fear. \n",
    "\n",
    "This illustrates the fact that the emotions expressed by a text are highly contextual. \n",
    "\n",
    "The lists' author's also caution: \"All words can potentially convey affective meaning.\"\n",
    "\n",
    "Notably, 832 headlines from the dataset contain zero words from the Affect Net emotion word list, and yet most of these are rated as having detectable emotions and emotional valence.\n",
    "\n",
    "\n",
    "Distinction between \"direct\" and \"indirect\" affective words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get df containing counts of words appearing in \n",
    "emotion_wordcount = get_emotion_wordcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216      Israeli woman's tirade spurs PM outrage\n",
       "267    Bigger, more aggressive rats infesting UK\n",
       "648                  One search does not fit all\n",
       "759            'WarioWare,' Wii make perfect fit\n",
       "987            Roddick, Murray score in San Jose\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['anger_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109    US to urge Nato Afghan spring offensive\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['disgust_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger         42\n",
       "disgust       14\n",
       "fear          54\n",
       "joy            0\n",
       "sadness       33\n",
       "surprise       0\n",
       "max         fear\n",
       "label          2\n",
       "Name: 109, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.iloc[109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33        TBS to pay $2M fine for ad campaign bomb scare\n",
       "140                      Firms on alert for letter bombs\n",
       "234    Memo from Frankfurt: Germany relives 1970s ter...\n",
       "292    Freed Muslim terror suspect says Britain is \"p...\n",
       "300    In rigorous test, talk therapy works for panic...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['fear_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Test to predict breast cancer relapse is approved\n",
       "16                    Asian nations urge Myanmar reform\n",
       "35                     Discovered boys bring shock, joy\n",
       "43    Protesters end strike as Nepal PM concedes dem...\n",
       "67              Google executive acts as goodwill envoy\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['joy_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31     Really?: The claim: the pill can make you put ...\n",
       "89                Walters on Trump: 'Poor, pathetic man'\n",
       "150                   BP CEO Browne to step down in June\n",
       "191                 Snow brings travel misery to England\n",
       "295                  Why gas follows oil up but not down\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['sadness_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "534                    Czechs, Poles get missile warning\n",
       "602              Thousands line up to get late flu shots\n",
       "608    Whether to save cord blood can be puzzle for p...\n",
       "672                'Grey's,' 'Betty,' 'Scrubs' get boost\n",
       "714             Area should get 3-5 inches of snow today\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_wordcount.loc[emotion_wordcount['surprise_count']>0]['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotion_wordcount.loc[(emotion_wordcount['anger_count']==0) & (emotion_wordcount['disgust_count']==0) & (emotion_wordcount['fear_count']==0) & (emotion_wordcount['joy_count']==0) & (emotion_wordcount['sadness_count']==0) & (emotion_wordcount['surprise_count']==0)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom class method to process text\n",
    "processor = Process_Text_Data()\n",
    "processor.transform(corpus_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bar charts showing headline counts for each category\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "emotion_df['max'].value_counts().plot(kind='bar')\n",
    "plt.title(\"Number of Headlines per Emotion Category\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "valence_df['label'].value_counts().plot(kind='bar')\n",
    "plt.xticks([0,1,2], [\"negative\", \"positive\", \"neutral\"])\n",
    "plt.title(\"Number of Headlines per Valence Category\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations among emotion categories\n",
    "plt.figure(figsize=(12,10))\n",
    "corr = emotion_df.iloc[:,:-1].corr()\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intensity Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot showing the disribution of intensity scores for each emotion category\n",
    "plt.figure(figsize=(12,10))\n",
    "emotion_df.iloc[:,:-1].boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there there are no rows with rating 0 for all emotion categories, \n",
    "emotion_df.loc[(emotion_df.anger==0)&(emotion_df.disgust==0)&(emotion_df.fear==0)&(emotion_df.joy==0)&(emotion_df.sadness==0)& (emotion_df.surprise==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot showing the disribution of valencescores \n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,3,1)\n",
    "valence_df.loc[valence_df['label']==0]['valence'].plot(kind='box')\n",
    "plt.xticks([1], labels=[\"Negative\"])\n",
    "plt.subplot(1,3,2)\n",
    "valence_df.loc[valence_df['label']==1]['valence'].plot(kind='box')\n",
    "plt.xticks([1], labels=[\"Positive\"])\n",
    "plt.subplot(1,3,3)\n",
    "valence_df.loc[valence_df['label']==2]['valence'].plot(kind='box')\n",
    "plt.xticks([1], labels=[\"Netural\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there there are a few rows with rating 0 for valence, \n",
    "valence_df.loc[(valence_df.valence==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Frequencies\n",
    "\n",
    "### Corpus Top Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with words as keys and word counts as values\n",
    "word_count_dict = {}\n",
    "\n",
    "voc = set()\n",
    "for row in corpus_df['text']:\n",
    "    for word in row.split():\n",
    "        voc.add(word)\n",
    "        \n",
    "for word in voc:\n",
    "    word_count_dict[word]=0\n",
    "    \n",
    "for row in corpus_df['text']:\n",
    "    for word in row.split():\n",
    "        word_count_dict[word]+=1\n",
    "        \n",
    "# make a df of word counts        \n",
    "word_count_df = pd.DataFrame({\"word\": [key for key in word_count_dict.keys()], \"count\": [val for val in word_count_dict.values()]})\n",
    "word_count_df.sort_values('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the 30 most used words in the corpus\n",
    "word_count_df[:30].plot(kind='barh', figsize=(10,15))\n",
    "labels = [i for i in word_count_df[:30]['word']]\n",
    "plt.yticks(ticks = range(30), labels = labels)\n",
    "plt.title(\"Most Frequently Used Words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Top Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_count_dict = {}\n",
    "\n",
    "bigrams_set = set()\n",
    "for row in corpus_df['text']:\n",
    "    for bigram in list(bigrams(row.split())):\n",
    "        bigrams_set.add(bigram)\n",
    "        \n",
    "        \n",
    "for bigram in bigrams_set:\n",
    "    bigram_count_dict[bigram]=0\n",
    "    \n",
    "for row in corpus_df['text']:\n",
    "    for bigram in list(bigrams(row.split())):\n",
    "        bigram_count_dict[bigram]+=1\n",
    "        \n",
    "# make a df of bigram counts        \n",
    "bigram_count_df = pd.DataFrame({\"bigram\": [key for key in bigram_count_dict.keys()], \"count\": [val for val in bigram_count_dict.values()]})\n",
    "bigram_count_df.sort_values('count', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_count_df[:15].plot(kind='barh', figsize=(8,10))\n",
    "labels = [i for i in bigram_count_df[:15]['bigram']]\n",
    "plt.yticks(ticks = range(15), labels = labels)\n",
    "plt.title(\"Most Frequently Used Bigrams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words Per Emotion Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(emotion_df.columns[0:-2]):\n",
    "    \n",
    "    indexes = []\n",
    "    for index, val in enumerate(emotion_df['max']):\n",
    "        if val==i:\n",
    "            indexes.append(index)\n",
    "    \n",
    "    single_emotion = corpus_df['text'][indexes] \n",
    "    word_string = ' '.join([str(i) for i in single_emotion])\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=500, random_state=42).generate(word_string)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(i)\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Words Per Valence Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0,1,2]:\n",
    "    \n",
    "    indexes = []\n",
    "    for index, val in enumerate(valence_df['label']):\n",
    "        if val==i:\n",
    "            indexes.append(index)\n",
    "    \n",
    "    single_valence = corpus_df['text'][indexes] \n",
    "    word_string = ' '.join([str(i) for i in single_valence])\n",
    "\n",
    "    wordcloud = WordCloud(width=800, height=500, random_state=42).generate(word_string)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    if i==0:\n",
    "        plt.title(\"Negative\")\n",
    "    elif i==1:\n",
    "        plt.title(\"Positive\")\n",
    "    else:\n",
    "        plt.title(\"Neutral/Low Valence\")\n",
    "    \n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length of Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for i in corpus_df['text']:\n",
    "    lengths.append(len(i.split()))\n",
    "    \n",
    "print(\"The average headline length is {0} words.\".format(np.round(sum(lengths)/len(lengths), 2)))\n",
    "print(\"The shortest headline length is {0} words.\".format(min(lengths)))\n",
    "print(\"The longest headline length is {0} words.\".format(max(lengths)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
